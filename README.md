# PaperIQ - Research Paper Insight Analyzer

**Milestone 1: Paper Upload & Parsing**

PaperIQ is a pure Python application that extracts and analyzes research papers. Upload a PDF and get automatic section identification, image extraction, and table detection with confidence scoring.

## ğŸš€ Features

- **ğŸ“¤ PDF Upload** - Upload research papers through a web interface
- **ğŸ“ Section Detection** - Automatically identify:
  - Abstract
  - Introduction
  - Methodology/Methods
  - Results/Experiments
  - Discussion
  - Conclusion
  - References
- **ğŸ–¼ï¸ Image Extraction** - Extract all figures and diagrams with metadata
- **ğŸ“Š Table Extraction** - Extract tables and convert to CSV format
- **âœ… Quality Validation** - Confidence scores and validation reports
- **ğŸ’¾ Persistent Storage** - SQLite database for data persistence

## ğŸ“‹ Requirements

- Python 3.9+
- pip

## ğŸ› ï¸ Installation

1. **Clone or navigate to the project:**
   ```bash
   cd /path/to/PaperIQ
   ```

2. **Create a virtual environment (recommended):**
   ```bash
   python -m venv venv
   source venv/bin/activate  # On Windows: venv\Scripts\activate
   ```

3. **Install dependencies:**
   ```bash
   pip install -r requirements.txt
   ```

4. **Copy environment configuration (optional):**
   ```bash
   cp .env.example .env
   # Edit .env to customize settings
   ```

## ğŸƒ Running the Application

Start the Streamlit app:

```bash
streamlit run app/main.py
```

The app will open in your browser at `http://localhost:8501`

## ğŸ“ Project Structure

```
paperiq/
â”œâ”€â”€ requirements.txt          # Python dependencies
â”œâ”€â”€ .env.example             # Configuration template
â”œâ”€â”€ .gitignore
â”œâ”€â”€ README.md
â”‚
â”œâ”€â”€ src/                     # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ parsers/             # PDF parsing logic
â”‚   â”‚   â”œâ”€â”€ pdf_extractor.py    # Text extraction with PyMuPDF
â”‚   â”‚   â”œâ”€â”€ section_detector.py # Section identification
â”‚   â”‚   â”œâ”€â”€ table_handler.py    # Table extraction with Camelot
â”‚   â”‚   â”œâ”€â”€ image_handler.py    # Image extraction
â”‚   â”‚   â””â”€â”€ text_cleaner.py     # Text preprocessing
â”‚   â”‚
â”‚   â”œâ”€â”€ storage/             # Data persistence
â”‚   â”‚   â”œâ”€â”€ db_handler.py       # SQLite operations
â”‚   â”‚   â””â”€â”€ file_manager.py     # File system operations
â”‚   â”‚
â”‚   â”œâ”€â”€ utils/               # Helper functions
â”‚   â”‚   â”œâ”€â”€ validators.py       # PDF and content validation
â”‚   â”‚   â”œâ”€â”€ logger_config.py    # Logging setup
â”‚   â”‚   â””â”€â”€ config.py           # App configuration
â”‚   â”‚
â”‚   â””â”€â”€ models/              # Data structures
â”‚       â””â”€â”€ paper_model.py      # Paper data classes
â”‚
â”œâ”€â”€ app/                     # Streamlit UI
â”‚   â”œâ”€â”€ main.py             # Main application entry
â”‚   â”œâ”€â”€ pages/
â”‚   â”‚   â”œâ”€â”€ 1_ğŸ“¤_Upload.py     # Upload and parse page
â”‚   â”‚   â””â”€â”€ 2_ğŸ“Š_Results.py    # View results page
â”‚   â”‚
â”‚   â””â”€â”€ components/          # Reusable UI components
â”‚       â”œâ”€â”€ upload_widget.py
â”‚       â”œâ”€â”€ section_viewer.py
â”‚       â”œâ”€â”€ image_gallery.py
â”‚       â””â”€â”€ validation_report.py
â”‚
â”œâ”€â”€ data/                    # Data directory (auto-created)
â”‚   â”œâ”€â”€ uploads/            # Uploaded PDF files
â”‚   â”œâ”€â”€ extracted/
â”‚   â”‚   â”œâ”€â”€ images/         # Extracted images
â”‚   â”‚   â””â”€â”€ tables/         # Extracted tables as CSV
â”‚   â””â”€â”€ paperiq.db          # SQLite database
â”‚
â””â”€â”€ tests/
    â””â”€â”€ sample_papers/      # Test PDFs for validation
```

## ğŸ”§ Configuration

Configuration options in `.env`:

| Setting | Default | Description |
|---------|---------|-------------|
| `MAX_PDF_SIZE_MB` | 50 | Maximum file size in MB |
| `ENABLE_OCR` | False | Enable OCR (future feature) |
| `MIN_SECTION_LENGTH` | 50 | Minimum section length in chars |
| `HIGH_CONFIDENCE_THRESHOLD` | 0.8 | High confidence score threshold |
| `MEDIUM_CONFIDENCE_THRESHOLD` | 0.6 | Medium confidence threshold |

## ğŸ“Š How It Works

### Processing Pipeline

1. **Upload** - Validate and save PDF file
2. **Text Extraction** - Extract text with layout info using PyMuPDF
3. **Image Extraction** - Extract embedded images
4. **Table Extraction** - Detect and extract tables using Camelot
5. **Section Detection** - Identify sections using pattern matching + layout analysis
6. **Validation** - Generate confidence scores and quality report
7. **Storage** - Save results to SQLite database

### Section Detection

Uses a two-phase approach:

1. **Pattern Matching** - Regex patterns for common section headers
2. **Layout Analysis** - Font size and bold formatting detection

Combined confidence scoring:
- **High (â‰¥80%)**: Pattern match + large font + bold
- **Medium (60-80%)**: Pattern match + layout feature
- **Low (<60%)**: Weak signals

## ğŸ¨ UI Features

- **Dashboard** - Overview with quick stats
- **Upload Page** - Drag & drop PDF upload with progress tracking
- **Results Page** - Tabbed view of sections, images, tables, and validation
- **Confidence Badges** - Color-coded confidence indicators
- **Export** - Download extracted tables as CSV

## âš ï¸ Known Limitations

- OCR not yet supported (digital PDFs only)
- Some complex table layouts may not extract correctly
- Multi-language support is limited

## ğŸ§ª Testing

Place test PDFs in `tests/sample_papers/` directory.

## ğŸ“ License

This project is for educational purposes.

## ğŸ¤ Contributing

This is a Milestone 1 implementation. Future milestones will add:
- Milestone 2: NLP analysis (summarization, keywords)
- Milestone 3: Multi-paper comparison
- Milestone 4: AI-powered insights
